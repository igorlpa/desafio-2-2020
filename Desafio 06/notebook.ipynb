{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 6 - LIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos conjuntos de dados em formato .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>graduacao</th>\n",
       "      <th>universidade</th>\n",
       "      <th>profissao</th>\n",
       "      <th>organizacao</th>\n",
       "      <th>pretende_fazer_cursos_lit</th>\n",
       "      <th>interesse_mba_lit</th>\n",
       "      <th>importante_ter_certificado</th>\n",
       "      <th>horas_semanais_estudo</th>\n",
       "      <th>como_conheceu_lit</th>\n",
       "      <th>total_modulos</th>\n",
       "      <th>modulos_iniciados</th>\n",
       "      <th>modulos_finalizados</th>\n",
       "      <th>certificados</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>620397030.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>UFF</td>\n",
       "      <td>Outros</td>\n",
       "      <td>Borracha</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfil6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>229931283.0</td>\n",
       "      <td>Bacharelado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Linkedin</td>\n",
       "      <td>42.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>480674907.0</td>\n",
       "      <td>Tecnólogo</td>\n",
       "      <td>UNIP</td>\n",
       "      <td>Sócio/Dono/Proprietário</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>perfil5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855</th>\n",
       "      <td>559626807.0</td>\n",
       "      <td>SEM FORMAÇÃO</td>\n",
       "      <td>UNIVERSIDADE NOVE DE JULHO</td>\n",
       "      <td>Advogado</td>\n",
       "      <td>Estado</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>226.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15856</th>\n",
       "      <td>743652801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FGV-RJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Siderurgica</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Outros</td>\n",
       "      <td>125.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>perfil1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id     graduacao                universidade  \\\n",
       "15852  620397030.0   Bacharelado                         UFF   \n",
       "15853  229931283.0   Bacharelado                         NaN   \n",
       "15854  480674907.0     Tecnólogo                        UNIP   \n",
       "15855  559626807.0  SEM FORMAÇÃO  UNIVERSIDADE NOVE DE JULHO   \n",
       "15856  743652801.0           NaN                      FGV-RJ   \n",
       "\n",
       "                     profissao  organizacao  pretende_fazer_cursos_lit  \\\n",
       "15852                   Outros     Borracha                        0.0   \n",
       "15853                 Advogado          NaN                        0.0   \n",
       "15854  Sócio/Dono/Proprietário          NaN                        0.0   \n",
       "15855                 Advogado       Estado                        0.0   \n",
       "15856                      NaN  Siderurgica                        1.0   \n",
       "\n",
       "       interesse_mba_lit  importante_ter_certificado  horas_semanais_estudo  \\\n",
       "15852                0.0                         1.0                    8.0   \n",
       "15853                0.0                         1.0                    7.0   \n",
       "15854                NaN                         1.0                    7.0   \n",
       "15855                0.0                         1.0                   10.0   \n",
       "15856                1.0                         1.0                    9.0   \n",
       "\n",
       "      como_conheceu_lit  total_modulos  modulos_iniciados  \\\n",
       "15852               NaN           10.0                NaN   \n",
       "15853          Linkedin           42.0               17.0   \n",
       "15854            Outros           30.0                9.0   \n",
       "15855               NaN          226.0              102.0   \n",
       "15856            Outros          125.0               98.0   \n",
       "\n",
       "       modulos_finalizados  certificados categoria  \n",
       "15852                  NaN           NaN   perfil6  \n",
       "15853                 15.0           NaN   perfil5  \n",
       "15854                  8.0           0.0   perfil5  \n",
       "15855                 93.0           1.0   perfil1  \n",
       "15856                 97.0           1.0   perfil1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('training_dataset.csv')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre o arquivo \"training_dataset.csv\", temos algumas informações gerais sobre os usuários da plataforma:\n",
    "\n",
    "**id**\n",
    "\n",
    "**graduacao**\n",
    "\n",
    "**universidade**\n",
    "\n",
    "**profissao**\n",
    "\n",
    "**organizacao**\n",
    "\n",
    "**pretende_fazer_cursos_lit**\n",
    "\n",
    "**interesse_mba_lit**\n",
    "\n",
    "**importante_ter_certificado**\n",
    "\n",
    "**horas_semanais_estudo**\n",
    "\n",
    "**como_conheceu_lit**\n",
    "\n",
    "**total_modulos**\n",
    "\n",
    "**modulos_iniciados**\n",
    "\n",
    "**modulos_finalizados**\n",
    "\n",
    "**certificados**\n",
    "\n",
    "**categoria**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15857 entries, 0 to 15856\n",
      "Data columns (total 15 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          13945 non-null  float64\n",
      " 1   graduacao                   13950 non-null  object \n",
      " 2   universidade                13920 non-null  object \n",
      " 3   profissao                   13977 non-null  object \n",
      " 4   organizacao                 13961 non-null  object \n",
      " 5   pretende_fazer_cursos_lit   13989 non-null  float64\n",
      " 6   interesse_mba_lit           14003 non-null  float64\n",
      " 7   importante_ter_certificado  13918 non-null  float64\n",
      " 8   horas_semanais_estudo       13959 non-null  float64\n",
      " 9   como_conheceu_lit           13915 non-null  object \n",
      " 10  total_modulos               13987 non-null  float64\n",
      " 11  modulos_iniciados           14044 non-null  float64\n",
      " 12  modulos_finalizados         13924 non-null  float64\n",
      " 13  certificados                13979 non-null  float64\n",
      " 14  categoria                   15857 non-null  object \n",
      "dtypes: float64(9), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            13945\n",
       "graduacao                         6\n",
       "universidade                     21\n",
       "profissao                        12\n",
       "organizacao                      11\n",
       "pretende_fazer_cursos_lit         2\n",
       "interesse_mba_lit                 2\n",
       "importante_ter_certificado        1\n",
       "horas_semanais_estudo             9\n",
       "como_conheceu_lit                 9\n",
       "total_modulos                   578\n",
       "modulos_iniciados               372\n",
       "modulos_finalizados             339\n",
       "certificados                     23\n",
       "categoria                         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Detalhamento do desafio: classificação multiclasse\n",
    "\n",
    "Este é um desafio cujo objetivo de negócio é a segmentação dos usuários de uma plataforma de ensino. Para tal, podemos utilizar duas abordagens: aprendizado de máquina supervisionado (classificação) ou não-supervisionado (clustering). Neste desafio será aplicada a classificação, pois é disponível um dataset já com \"labels\", ou em outras palavras, já com exemplos de dados juntamente com a variável alvo.\n",
    "\n",
    "Na biblioteca scikit-learn temos diversos algoritmos para classificação. O participante é livre para utilizar o framework que desejar para completar esse desafio.\n",
    "\n",
    "Neste notebook será mostrado um exeplo de uso do algoritmo \"Decision Tree\" para classificar parte dos estudantes em seis diferentes perfís."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna-alvo neste desafio é a coluna ``categoria``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processando o dataset antes do treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo todas as linhas que possuem algum valor nulos em determinadas colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando o método Pandas **DataFrame.dropna()** você pode remover todas as linhas nulas do dataset.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função para deletar todas as linhas com valor NaN na coluna ``certificados'' e ``total_modulos'':\n",
    "df_training_dataset = df_training_dataset.dropna(axis='index', how='any', subset=['certificados', 'total_modulos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação DropNA: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processando valores NaN com o SimpleImputer do sklearn\n",
    "\n",
    "Para os valores NaN, usaremos a substituição pela constante 0 como **exemplo**.\n",
    "\n",
    "Você pode escolher a estratégia que achar melhor para tratar os valores nulos :)\n",
    "\n",
    "Docs: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simpleimputer#sklearn.impute.SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "impute_zeros = SimpleImputer(\n",
    "    missing_values=np.nan,\n",
    "    strategy='constant',\n",
    "    fill_value=0,\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo os dados ausentes do conjunto de dados antes da primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset.isnull().sum(axis = 0)))\n",
    "\n",
    "# Aplicando a transformação ``SimpleImputer`` no conjunto de dados base\n",
    "impute_zeros.fit(X=df_training_dataset)\n",
    "\n",
    "# Reconstruindo um Pandas DataFrame com os resultados\n",
    "df_training_dataset_imputed = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_training_dataset\n",
    "    ),\n",
    "    columns=df_training_dataset.columns\n",
    ")\n",
    "\n",
    "# Exibindo os dados ausentes do conjunto de dados após a primeira transformação (df)\n",
    "print(\"Valores nulos no df_training_dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_imputed.isnull().sum(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando colunas indesejadas\n",
    "\n",
    "Vamos **demonstrar** abaixo como usar o método **DataFrame.drop()**.\n",
    "\n",
    "Docs: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_imputed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns = df_training_dataset_imputed.drop(columns=['id', 'graduacao', 'universidade', 'organizacao', 'como_conheceu_lit'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_dataset_rmcolumns.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "As colunas removidas acima são apenas para fim de exemplo, você pode usar as colunas que quiser e inclusive criar novas colunas com dados que achar importantes!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de de variáveis categóricas\n",
    "\n",
    "Como mencionado antes, os computadores não são bons com variáveis \"categóricas\" (ou strings).\n",
    "\n",
    "Dado uma coluna com variável categórica, o que podemos realizar é a codificação dessa coluna em múltiplas colunas contendo variáveis binárias. Esse processo é chamado de \"one-hot-encoding\" ou \"dummy encoding\". Se você não é familiarizado com esses termos, você pode pesquisar mais sobre isso na internet :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando variáveis categóricas com o método Pandas ``get_dummies()''\n",
    "df_training = pd.get_dummies(df_training_dataset_rmcolumns, columns=['profissao'])\n",
    "df_training.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "A coluna **categoria** deve ser mantida como uma string. Você não precisa processar/codificar a variável-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando um classificador com base em uma árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionando FEATURES e definindo a variável TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_training[\n",
    "    [\n",
    "        'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "        'importante_ter_certificado', 'horas_semanais_estudo', 'total_modulos',\n",
    "        'modulos_iniciados', 'modulos_finalizados', 'certificados',\n",
    "        'profissao_0', 'profissao_Advogado', 'profissao_Analista',\n",
    "        'profissao_Analista Senior', 'profissao_Assessor',\n",
    "        'profissao_Coordenador', 'profissao_Diretor', 'profissao_Engenheiro',\n",
    "        'profissao_Gerente', 'profissao_Outros', 'profissao_SEM EXPERIÊNCIA',\n",
    "        'profissao_Supervisor', 'profissao_Sócio/Dono/Proprietário'\n",
    "    ]\n",
    "]\n",
    "target = df_training['categoria']  ## NÃO TROQUE O NOME DA VARIÁVEL TARGET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo nosso conjunto de dados em conjuntos de treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando uma árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para creacion de modelos basados en arbol de desición\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo previsões na amostra de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando a qualidade do modelo através da matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['parfil1', 'perfil2', 'perfil3', 'perfil4', 'perfil5', 'perfil6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring dos dados necessários para entregar a solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download da \"folha de respostas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-3/master/to_be_scored.csv\n",
    "df_to_be_scored = pd.read_csv(r'to_be_scored.csv')\n",
    "df_to_be_scored.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção!\n",
    "\n",
    "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"categoria\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_to_be_scored.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Atenção!\n",
    "\n",
    "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
    "\n",
    "# Não remova ou adicione linhas na folha de respostas. \n",
    "\n",
    "# Não altere a ordem das linhas na folha de respostas.\n",
    "\n",
    "# Ao final, as 1000 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Removendo linhas com valores NaN em \"certificados\" e \"total_modulos\"\n",
    "df_to_be_scored_1 = df_to_be_scored.dropna(axis='index', how='any', subset=['certificados', 'total_modulos'])\n",
    "\n",
    "# 2 - Inputando zeros nos valores faltantes\n",
    "impute_zeros.fit(X=df_to_be_scored_1)\n",
    "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
    "    data=impute_zeros.transform(\n",
    "        X=df_to_be_scored_1\n",
    "    ),\n",
    "    columns=df_to_be_scored_1.columns\n",
    ")\n",
    "\n",
    "# 3 - Remoção de colunas\n",
    "df_to_be_scored_3 = df_to_be_scored_2.drop(columns=['id', 'graduacao', 'universidade', 'organizacao', 'como_conheceu_lit'], inplace=False)\n",
    "\n",
    "# 4 - Encoding com \"dummy variables\"\n",
    "df_to_be_scored_4 = pd.get_dummies(df_to_be_scored_3, columns=['profissao'])\n",
    "\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training[\n",
    "    [\n",
    "        'pretende_fazer_cursos_lit', 'interesse_mba_lit',\n",
    "        'importante_ter_certificado', 'horas_semanais_estudo', 'total_modulos',\n",
    "        'modulos_iniciados', 'modulos_finalizados', 'certificados',\n",
    "        'profissao_0', 'profissao_Advogado', 'profissao_Analista',\n",
    "        'profissao_Analista Senior', 'profissao_Assessor',\n",
    "        'profissao_Coordenador', 'profissao_Diretor', 'profissao_Engenheiro',\n",
    "        'profissao_Gerente', 'profissao_Outros', 'profissao_SEM EXPERIÊNCIA',\n",
    "        'profissao_Supervisor', 'profissao_Sócio/Dono/Proprietário'\n",
    "    ]\n",
    "].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "Para todas colunas que não existirem no \"df_to_be_scored\", você pode usar a técnica abaixo para adicioná-las:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_be_scored_4['profissao_0'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dtc.predict(df_to_be_scored_4)\n",
    "df_to_be_scored_4['target'] = y_pred\n",
    "df_to_be_scored_4.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save_data(file_name=\"results.csv\", data=df_to_be_scored_4.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atenção\n",
    "\n",
    "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Parabéns!\n",
    "\n",
    "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
    "\n",
    "# https://lit.maratona.dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
